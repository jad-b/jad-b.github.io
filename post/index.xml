<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on while true: continue</title>
    <link>http://jad-b.github.io/post/</link>
    <description>Recent content in Posts on while true: continue</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 28 May 2016 07:42:13 -0400</lastBuildDate>
    <atom:link href="http://jad-b.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Why I&#39;m Not Getting My Graduate Degree (Yet).</title>
      <link>http://jad-b.github.io/post/Why%20Not%20School/</link>
      <pubDate>Sat, 28 May 2016 07:42:13 -0400</pubDate>
      
      <guid>http://jad-b.github.io/post/Why%20Not%20School/</guid>
      <description>&lt;p&gt;In case you &lt;em&gt;haven&amp;rsquo;t&lt;/em&gt; heard, data science is big right now. And when you say
&amp;ldquo;data science&amp;rdquo; you also get &amp;ldquo;machine learning&amp;rdquo; packaged in for free, and that stuff&amp;rsquo;s
cool, so even better!  Plus, the booming field of data engineering is making
all &lt;em&gt;kinds&lt;/em&gt; of advances in dealing with Big Data, like real-time streaming from
massive amounts of data sources, and you can&amp;rsquo;t tell me that&amp;rsquo;s not going to be
necessity for the widgets of tomorrow.&lt;/p&gt;

&lt;p&gt;Maybe, like me, you&amp;rsquo;d like to learn more about all of this. And perhaps,
like me, you&amp;rsquo;ve got a job, and maybe it&amp;rsquo;s a pretty good job. But the knee-jerk
response you hear is, &amp;ldquo;Get your master&amp;rsquo;s degree&amp;rdquo;, or even further, a Ph.D. And
this is a problem. Not just the money&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:0dd3d526e46395327a1e0149bbb97370:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:0dd3d526e46395327a1e0149bbb97370:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, or the potential move, or the
commitment, but the lack of &lt;em&gt;optimality&lt;/em&gt;: is this the best way to learn?&lt;/p&gt;

&lt;p&gt;How much of your undergraduate education got left in a notebook, or existed
only for a test? Do you remember anything you didn&amp;rsquo;t actually apply? Did you
ever sit bored in class? How about completely lost (at least a more useful
feeling)? What a waste. You, or someone, &lt;em&gt;paid&lt;/em&gt; for that lost time.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at what a modern &lt;a href=&#34;https://www.google.com/webhp?sourceid=chrome-instant&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=define%20auto%20didact&#34;&gt;autodidact&lt;/a&gt; can utilize when learning data
science:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Take advantage of a broad selection of online courses to gain initial
exposure to concepts and an beginner to intermediate understanding.&lt;/li&gt;
&lt;li&gt;Anyone can buy textbooks, which are useful twice: once for their table of
contents to tell you what the field looks like, and again for when you need
the details.&lt;/li&gt;
&lt;li&gt;Access to essentially all academic literature, if and when that necessity arises.&lt;/li&gt;
&lt;li&gt;Take advantage of a &lt;em&gt;huge&lt;/em&gt; amount of open-source software.&lt;/li&gt;
&lt;li&gt;Get experience from Kaggle competitions, which have directly led to numerous
people getting jobs.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This may seem like a knock against all higher education. It is not. If your
goal is to research, or simply learn all you can about a topic, then I think
academia is the perfect, and perhaps only, option. And there are many things
going for higher-education: Direct access to experts and
prohibitively-expensive equipment, a guaranteed path, a like-minded community,
networking and institutional reputation, and job placement services at the end.
I believe each of those points has a self-learning counter-part, and that
comparison would deserve its own write-up, in the interest of keeping this
focused.&lt;/p&gt;

&lt;p&gt;Ask yourself this: After a year of self-tutelage, would you be &lt;em&gt;worse&lt;/em&gt; off if
you &lt;em&gt;then&lt;/em&gt; decided to start a graduate program? Or, as I believe, would you
find yourself a better student, questions in mind, with answers to satisfy?
The self-generated portfolio from your year of self-teaching would certainly
assist in admissions.&lt;/p&gt;

&lt;p&gt;And, of course, you might find you don&amp;rsquo;t need that graduate&amp;rsquo;s program at all,
or that your interests have changed as a result of what you learned yourself.
No one knows you better than yourself. It won&amp;rsquo;t be easy. You&amp;rsquo;ll have to learn
how &lt;em&gt;you&lt;/em&gt; learn: how to tell when you&amp;rsquo;ve dead-ended, when you&amp;rsquo;re coasting.
You&amp;rsquo;ll have to find your own projects. And you&amp;rsquo;ll have to manage your own
motivation, since you won&amp;rsquo;t have a course progression or grades to praise you.
These are hard things to do. They are also worthwhile things to do. You get to
take them with you the rest of your life.&lt;/p&gt;

&lt;p&gt;I am taking this path. It&amp;rsquo;s already been difficult. Progress feels like drawing
loops without lifting the pen from the page; you go forwards, then sideways,
then backwards, but you never end up where you started, and that becomes your
new starting point. I want to find more people embarking on this new form of
open, project-based, crowd-sourced, self-directed education, no matter their
field of interest. Hopefully our loops will cross paths.&lt;/p&gt;

&lt;p&gt;I write this more for myself than anyone, but don&amp;rsquo;t we always?&lt;/p&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:0dd3d526e46395327a1e0149bbb97370:1&#34;&gt;&lt;p&gt;Because average annual tuition costs are $30-40k, and even with
50% financial aid, this is still tens of thousands of dollars. And you need
health insurance. And if you want to get it done fast, you&amp;rsquo;re almost certainly
not working, although a 2-year degree &lt;em&gt;is&lt;/em&gt; possible if you commit the rest of
your non-working hours to school, with an associated hit to your quality of
life.&lt;/p&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:0dd3d526e46395327a1e0149bbb97370:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ODSC 2016 - Friday</title>
      <link>http://jad-b.github.io/post/ODSC2016%20-%20Friday/</link>
      <pubDate>Fri, 20 May 2016 10:21:22 -0400</pubDate>
      
      <guid>http://jad-b.github.io/post/ODSC2016%20-%20Friday/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;Goto&lt;/strong&gt;: &lt;a href=&#34;No page found with path or logical name &#34;post/ODSC2016 - Saturday.md&#34;.
&#34;&gt;Saturday&lt;/a&gt; &amp;amp;
&lt;a href=&#34;No page found with path or logical name &#34;post/ODSC2016 - Sunday.md&#34;.
&#34;&gt;Sunday&amp;rsquo;s&lt;/a&gt; notes.&lt;/p&gt;

&lt;h1 id=&#34;friday-morning:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Friday - Morning&lt;/h1&gt;

&lt;h2 id=&#34;building-a-recommendation-system:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Building a Recommendation System&lt;/h2&gt;

&lt;p&gt;Speaker: &lt;a href=&#34;https://www.linkedin.com/in/cfregly&#34;&gt;Chris Fregly&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;spark:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Spark&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;On Spark &amp;amp; Tableau (or Redshift):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;When you&amp;rsquo;re connecting Tableau to Spark, it&amp;rsquo;s all going through one JVM, the HiveThrift
server (which converts SQL into Java talk).  You want to make sure you&amp;rsquo;re pushding down as
much computation as possible to Spark, saving the HiveThrift server cycles. This way you
collect the results of your computation for display in your visualization engine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;On Graph Analysis&lt;/strong&gt;
If you&amp;rsquo;re doing network analysis using Spark, look at using GraphFrames over GraphX.
GraphFrames is fully supported in Spark2. Both are only good for offline graph analytics;
transactional graph queries should be loaded into a dedicated Graph DB like Neo4j.&lt;/p&gt;

&lt;p&gt;People don&amp;rsquo;t seem to test these systems! I suppose if you&amp;rsquo;re already monitoring
performance and model prediction accuracy, you &lt;em&gt;are&lt;/em&gt; testing them. And it&amp;rsquo;d be easy enough
to mock up I/O for subsets to confirm functionality.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Spark - Packages&lt;/code&gt;: a marketplace for Spark packages&lt;/p&gt;

&lt;h4 id=&#34;spark-2-0:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Spark 2.0&lt;/h4&gt;

&lt;p&gt;Big focus on codegen: A &lt;code&gt;map&lt;/code&gt; followed by a &lt;code&gt;filter&lt;/code&gt; will get re-written into a single method, reducing function calls.
Relies on &lt;a href=&#34;http://unkrig.de/w/Janino&#34;&gt;Project Janino&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Lot of talk about
&lt;a href=&#34;https://databricks.com/blog/2015/04/28/project-tungsten-bringing-spark-closer-to-bare-metal.html&#34;&gt;Tungsten&lt;/a&gt;,
to include new low-level data structures, code generation, and more.&lt;/p&gt;

&lt;p&gt;Spark 2.0 will support exporting models as PMML. PMML is the common data representation of ML models.&lt;/p&gt;

&lt;h4 id=&#34;probabilistic-data-structures:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Probabilistic data structures&lt;/h4&gt;

&lt;p&gt;Paco Nathan: Good work on probabilistic structures. &lt;a href=&#34;https://www.linkedin.com/in/ceteri&#34;&gt;https://www.linkedin.com/in/ceteri&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;When you allow the possibility of error into your queries, a 14 bit structure can store
1e9 counts, w/ an error of .81%,&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;HyperLogLog&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Particular hash function used by HLL guarantees the data will be uniformly distributed.
Something about taking subsets of the data.&lt;/li&gt;
&lt;li&gt;If you have guaranteed uniform distribution, you can check for a distinct number of
users by only checking the beginning of the structure. Similar to Numenta&amp;rsquo;s SDR
bitmasks.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CountMin Sketch&lt;/strong&gt;

&lt;ul&gt;
&lt;li&gt;Creates a (# of hash functions, # of bits) table. Every item gets an entry in each
row (per hash function). Each table cell is a count of how many times a hash
function has created that bit value. When you want the count for an item, you hash
it, and take the &lt;em&gt;minimum&lt;/em&gt; of all rows. You&amp;rsquo;re guaranteed to always be &amp;gt;= the &lt;em&gt;true&lt;/em&gt;
count of the item. The &lt;code&gt;&amp;gt;&lt;/code&gt; is due to overlap with other items.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Also: &lt;a href=&#34;https://en.wikipedia.org/wiki/Bloom_filter&#34;&gt;&lt;strong&gt;Bloom Filters&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Size in Memory of 1e6 item

&lt;ul&gt;
&lt;li&gt;HyperLogLog: 16,472 bytes&lt;/li&gt;
&lt;li&gt;Naive Array: 4,800,016 bytes&lt;/li&gt;
&lt;li&gt;CountMin Sketch: 310,944 bytes&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Came across this &lt;a href=&#34;https://en.wikipedia.org/wiki/Bloom_filter&#34;&gt;overview&lt;/a&gt; when looking up
info on HyperLogLog.&lt;/p&gt;

&lt;h3 id=&#34;lessons-from-netflix:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Lessons from Netflix&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;A logging company that also streams movies&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Chris worked on the Netflix Streaming Services team as a Data Engineer, and his experience
there came up in many examples.&lt;/p&gt;

&lt;p&gt;Stated &amp;ldquo;Netflix tends to build over buy&amp;rdquo;; if you take their &lt;a href=&#34;https://github.com/netflix&#34;&gt;GitHub
repo&lt;/a&gt; organization as a good representation of what they&amp;rsquo;ve
built, that&amp;rsquo;s 111 repos worth of projects (as of 2016May23, using &lt;code&gt;curl&lt;/code&gt; + &lt;code&gt;jq&lt;/code&gt;). Of
course, they&amp;rsquo;ve already severly limited how much they have to build by heavily leveraging
the capabilities of AWS.&lt;/p&gt;

&lt;p&gt;Noted they&amp;rsquo;ve been using &lt;a href=&#34;https://prestodb.io/&#34;&gt;Presto&lt;/a&gt;, a ANSI SQL tool for querying
multiple datasources at once, for ad-hoc analytics. Presto replaces Apache Hive, as long
as you don&amp;rsquo;t need fault tolerance, as it stores its intermediate results in memory.&lt;/p&gt;

&lt;p&gt;As the number of microservices grew, breakages in one API tended to bring down a &lt;em&gt;lot&lt;/em&gt; of
services. Interestingly, &lt;a href=&#34;https://www.linkedin.com/in/adriancockcroft&#34;&gt;Adrian Cockcroft&lt;/a&gt; mentioned these breakages
tend to show one-level away from the root of the problem in the &lt;em&gt;dependent&lt;/em&gt; APIs, which is
echoes a lesson learned in Athletic Training: Pain starts up the chain. To combat these
breakages, they developed &lt;a href=&#34;https://www.linkedin.com/in/adriancockcroft&#34;&gt;Hystrix&lt;/a&gt;.
Hystrix implements the &lt;a href=&#34;http://martinfowler.com/bliki/CircuitBreaker.html&#34;&gt;Circuit Breaker
pattern&lt;/a&gt;. I haven&amp;rsquo;t dived into the
library well enough to know exactly, but I know it solved a few problems:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;What broke?&lt;/li&gt;
&lt;li&gt;What&amp;rsquo;s the fallback?&lt;/li&gt;
&lt;li&gt;Metric gathering on API requests.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Also: &lt;code&gt;Hystrix&lt;/code&gt; can collapse multiple requests for the same object into one. Natural if
you&amp;rsquo;ve got a connector library going in between all of your API requests.&lt;/p&gt;

&lt;p&gt;Has Hystrix been re-implemented in any other languages?&lt;/p&gt;

&lt;h4 id=&#34;data-pipeline:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Data Pipeline&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.slideshare.net/cfregly/dc-spark-users-group-march-15-2016-spark-and-netflix-recommendations&#34;&gt;Slideshare here, goto slide 104&lt;/a&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;v1 - Producers =&amp;gt; Chukwa =&amp;gt; S3 =&amp;gt; EMR&lt;/li&gt;
&lt;li&gt;v2 - Producers =&amp;gt; Chukwa {=&amp;gt; S3 =&amp;gt; EMR} &amp;amp; {=&amp;gt; Kafka =&amp;gt; Stream Consumers &amp;amp; more}&lt;/li&gt;
&lt;li&gt;v3 - Producers =&amp;gt; Kafka =&amp;gt; Router =&amp;gt; {S3, ElasticSearch, {Kafka =&amp;gt; Stream Consumers}}&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Netflix runs a 10k node Memcached cluster that ML models get loaded into, amongst apparently everything else.&lt;/p&gt;

&lt;h4 id=&#34;the-netflix-prize:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;The Netflix Prize&lt;/h4&gt;

&lt;p&gt;Background: Given (movieID, userID, userRating, timestamp), improve predictions by 10%.
For a long time, the improvment was stuck around 7%. The key was when &lt;em&gt;timestamp&lt;/em&gt; got
incorporated into the predictive models. Essentially, they had to adjust for each humans&amp;rsquo;
bias. Some examples of said bias adjustments:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Alice effect: Alice rates lower than avg.&lt;/li&gt;
&lt;li&gt;Inception effect: Certain movies always get rated above avg&lt;/li&gt;
&lt;li&gt;Overall mean rating of a movie; high ratings encourage high ratings&lt;/li&gt;
&lt;li&gt;# of people who&amp;rsquo;ve rated a movie&lt;/li&gt;
&lt;li&gt;# of days since user&amp;rsquo;s first rating&lt;/li&gt;
&lt;li&gt;# of days since movie&amp;rsquo;s first rating&lt;/li&gt;
&lt;li&gt;Mood, time of day, day of week&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&#34;friday-afternoon:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Friday - Afternoon&lt;/h1&gt;

&lt;h2 id=&#34;deploying-serving-models:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Deploying &amp;amp; Serving models&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://tensorflow.github.io/serving/&#34;&gt;TensorFlow Serving&lt;/a&gt; provides a means of deploying
and running predictions on the models.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Dstream&lt;/code&gt; is the RDD of Spark Streaming; the mini-batch that&amp;rsquo;s just come in.
Holden Karrau - High Performance Spark talks about using RDDs in place of DataFrames&lt;/p&gt;

&lt;p&gt;What he&amp;rsquo;d use in a Production-ready system today:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Workflow: Airflow. Describe DAGs of tasks in Python.&lt;/li&gt;
&lt;li&gt;Extract-Transform-Load (ETL): PySpark. More Python than Java/Scala datasci people running around.&lt;/li&gt;
&lt;li&gt;Serving layer: Redis. Rock-solid, very fast.&lt;/li&gt;
&lt;li&gt;Data Stitching: nifi (maybe). Collects info from many many sources and convert into a single format.&lt;/li&gt;
&lt;li&gt;Storage: Elasticsearch to begin, and maybe forever. Scales well, good APIs; use it until you can&amp;rsquo;t.

&lt;ul&gt;
&lt;li&gt;Spark-Elasticsearch connector is very advanced; takes advantage of data locality&lt;/li&gt;
&lt;li&gt;Starting to tout itself as a GraphDB?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Monitoring: Ganglia.&lt;/li&gt;
&lt;li&gt;Logging: ELK fo&amp;rsquo; sho&amp;rsquo;&lt;/li&gt;
&lt;li&gt;Queueing: Kafka, if you have the ops team to support it. Otherwise, check out AWS Kinesis.&lt;/li&gt;
&lt;li&gt;Streaming

&lt;ul&gt;
&lt;li&gt;Kafka Streams or Flink. May want to &amp;ldquo;write to the Apache Beam API&amp;rdquo; - came out of Google.&lt;/li&gt;
&lt;li&gt;Storm is proven, but not getting a lot of new development. Twitter has written an API-compatible replacement
called Heron.&lt;/li&gt;
&lt;li&gt;Flink has a first-class processing for Complex Data Processing - whatever that
means.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Machine Learning: Depends on your language preference. If Python, then TensorFlow, sklearn, nltk.&lt;/li&gt;
&lt;li&gt;IDL: Spark is &lt;em&gt;all about&lt;/em&gt; Parquet. In-memory version is Apache Arrow.

&lt;ul&gt;
&lt;li&gt;SparkSQL is the most mature. Edit: A later speaker from Terabyte remarked on
SparkSQL being the most &lt;em&gt;immature&lt;/em&gt;, when compared to Apache Hive, Impala, Drill.&lt;/li&gt;
&lt;li&gt;Any project Michael Armbrust is on is going to be developed well&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;good-cool-ideas:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Good &amp;amp; Cool ideas&lt;/h2&gt;

&lt;p&gt;Spark&amp;rsquo;s &lt;code&gt;new StandardScaler=(withMean=True, withStd=False)&lt;/code&gt; lets you toggle how you feature scale.
PCA wants mean normalization, without std dev, but linear regression will want both.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;TextRank&lt;/code&gt;: Finds the sentence that best summarizes the corpus.&lt;/p&gt;

&lt;p&gt;Cluster density can be measured by WSSSE (Within Set Sum of Squared Errors); lower is better.&lt;/p&gt;

&lt;p&gt;Speaker mentioned anecdotally that 2 or 3 friends in the last 6 months had ditched
Cassandra clusters in favor of ElasticSearch.&lt;/p&gt;

&lt;p&gt;You don&amp;rsquo;t want to be doing read-heavy analytics on your write-heavy Cassandra
cluster; either have two separate clusters and setup replication from W=&amp;gt;R, or
read the SSTable files off the disk.&lt;/p&gt;

&lt;p&gt;StitchFix - Fill out preferences for clothes, then a stylist selects five items to ship you. Anything you send back you
fill out why you don&amp;rsquo;t like it. NLP interpets the written response, neural nets learn the style, and they&amp;rsquo;ll even ship
feedback to the designers saying what they&amp;rsquo;ve learned.&lt;/p&gt;

&lt;p&gt;Interesting thing to note: Often mentioned new technologies as a &amp;ldquo;recruiting point&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;skflow: A scikit-learn API compatible replacment with TensorFlow as a backend.&lt;/p&gt;

&lt;h2 id=&#34;resources:5a52b66b245ed92b1d2f83a5b6b5f33d&#34;&gt;Resources&lt;/h2&gt;

&lt;p&gt;&amp;ldquo;Jupyter notebooks for developers&amp;rdquo; &amp;amp; &amp;ldquo;Matplotlib for Developers&amp;rdquo; from O&amp;rsquo;Reilly.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gradient Descent: Ascending</title>
      <link>http://jad-b.github.io/post/Gradient%20Descent%20Ascending/</link>
      <pubDate>Fri, 13 May 2016 07:20:33 -0400</pubDate>
      
      <guid>http://jad-b.github.io/post/Gradient%20Descent%20Ascending/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Gradient descent keeps ascending my cost.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;Funny story&lt;/em&gt;, the issue wasn&amp;rsquo;t with the gradient descent implementation at all, but rather
the cost function(least squares). I was calculating my error by subtracting my
predicted values from the actual values(y), &lt;code&gt;$error = predicted - y$&lt;/code&gt;, instead of the other
way around, &lt;code&gt;$ error = y - predicted$&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This washed out when it came to calculating cost, since you end up squaring the error:&lt;/p&gt;

&lt;div&gt;$$
    J(\theta) = \frac{1}{2m}\sum_{i=1}^m(h_{\theta}(x^{i}) - y^{i})^{2}
$$&lt;/div&gt;

&lt;p&gt;but it &lt;em&gt;doesn&amp;rsquo;t&lt;/em&gt; get squared when you calculate the gradient:&lt;/p&gt;

&lt;div&gt;$$
    \theta_{j} := \alpha\frac{1}{m}\sum_{i=1}^m (h_{\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}
$$&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Testing Timeouts In Go With Channel Selects</title>
      <link>http://jad-b.github.io/post/Testing%20Timeouts%20in%20Go/</link>
      <pubDate>Thu, 05 May 2016 00:00:00 +0000</pubDate>
      
      <guid>http://jad-b.github.io/post/Testing%20Timeouts%20in%20Go/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import (
    &amp;quot;net&amp;quot;
    &amp;quot;testing&amp;quot;
    &amp;quot;time&amp;quot;
)

func TestAddrResolve(t *testing.T) {
    network, addr := &amp;quot;ip4&amp;quot;, &amp;quot;127.0.0.125:44151&amp;quot;
    addrChan := make(chan error)

    // Attempt to resolve IP addr
    go func(ch chan error) {
        _, err := net.DialTimeout(network, addr, 1 * time.Second)
        addrChan &amp;lt;- err
    }(addrChan)

    // Now, see who returns a msg first
    select {
    case e := &amp;lt;-addrChan:
        if e == nil {
            t.Fatalf(&amp;quot;%s://%s should fail to resolve&amp;quot;, network, addr)
        } else if testing.Verbose() { // Success!
            t.Logf(&amp;quot;Call to %s://%s timed out.\nError\n\t%s&amp;quot;, network, addr, e)
        }
    case &amp;lt;-time.After(1 * time.Second):
        t.Fatal(&amp;quot;Address resolution failed to timeout in one second.&amp;quot;)
    }
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Testing Distributed Systems</title>
      <link>http://jad-b.github.io/post/Testing%20Distributed%20Systems/</link>
      <pubDate>Tue, 19 Apr 2016 14:52:38 -0400</pubDate>
      
      <guid>http://jad-b.github.io/post/Testing%20Distributed%20Systems/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;TL;DR: Takeaways&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Always, always, always handle errors appropriately. No &lt;code&gt;pass&lt;/code&gt;, no &lt;code&gt;/* TODO
*/&lt;/code&gt;. &lt;em&gt;Something&lt;/em&gt; in the chain needs to verify it&amp;rsquo;s handled.&lt;/li&gt;
&lt;li&gt;Using 3 nodes lets you reproduce 98% of error cases in distributed systems.&lt;/li&gt;
&lt;li&gt;77% of catastrophic failures can be reproduced through unit tests&lt;/li&gt;
&lt;li&gt;Log aggressively, and on both sides of events (message passing).&lt;/li&gt;
&lt;li&gt;The big 5 error-ing events:

&lt;ol&gt;
&lt;li&gt;Startup&lt;/li&gt;
&lt;li&gt;Writes from client&lt;/li&gt;
&lt;li&gt;Node down/unreachable&lt;/li&gt;
&lt;li&gt;Configuration change&lt;/li&gt;
&lt;li&gt;Node join&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a work project involving multiple moving pieces begins the move from
proof-of-concept to preparing for production traffic, the various
pieces are beginning to knit into a whole. In particular, a client-driven event
requires that a list of registered services receive an update. Simple enough,
but failure in this system would result in bad API traffic routing, or worse,
all APIs becoming externally unavailable. Undesirable!&lt;/p&gt;

&lt;p&gt;My previous experiences involved nothing more distributed than your basic
web-server=&amp;gt;DB setup, so I took this as an opportunity to learn from other&amp;rsquo;s
mistakes. Searching around turns up the following advice:&lt;/p&gt;

&lt;h3 id=&#34;simple-testing-can-prevent-most-critical-failures:fab8ffd47911301da93228e4cb7d5640&#34;&gt;Simple Testing Can Prevent Most Critical Failures&lt;/h3&gt;

&lt;p&gt;A whitepaper&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fab8ffd47911301da93228e4cb7d5640:whitepaper&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:fab8ffd47911301da93228e4cb7d5640:whitepaper&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; out of the University of Toronto with some incredible
statistics on avoiding the worst-of-the-bad: catastrophic failures&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:fab8ffd47911301da93228e4cb7d5640:catfail&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:fab8ffd47911301da93228e4cb7d5640:catfail&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;. They
attribute 92% of CFs to bad error handling, with a further breakdown of&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;35% due to

&lt;ul&gt;
&lt;li&gt;Catching but not doing anything about the error&lt;/li&gt;
&lt;li&gt;Aborting on an overly-general error (java&amp;rsquo;s &lt;code&gt;Throwable&lt;/code&gt;, Python&amp;rsquo;s
&lt;code&gt;except:&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;A TODO/FIXME in place, but no handling&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;And 23% on aborting on a non-fatal error (failed to delete a temporary file)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;77%&lt;/strong&gt; of these failures they could reproduce using only unit tests. Admittedly,
this is their example unit test:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public void testLogRollAfterSplitStart {
    // Create HBase cluster with 1 master and 2 Region Servers
    startMiniCluster();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;which may stretch your imagining of unit tests. I believe what they were
getting at is that the problems are testable within the scope of a single
function&amp;rsquo;s setup/run/cleanup scope. Also, when your definition of unit test is
&amp;ldquo;code that I wrote&amp;rdquo;, and the code that you wrote was HBase, that&amp;rsquo;s quite the
scope.&lt;/p&gt;

&lt;p&gt;Oh, and how about this: &lt;strong&gt;98% of problems could be recreated using no more than
3 nodes&lt;/strong&gt;. Your 120 node Cassandra cluster&amp;rsquo;s dying? Odds are, you only need
three players to recreate it locally.&lt;/p&gt;

&lt;p&gt;An interesting point of difference the author&amp;rsquo;s noted between distributed and
non-distributed systems was that distributed systems tend to have much better
logging. As such, 84% of the studied failures had their triggering events
logged. They logged so much that the author&amp;rsquo;s recommended more advanced log
analysis techniques than a simple &lt;code&gt;grep ERROR&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;And to wrap this up: Starting up was the most dangerous time for a process, as
summarized under &amp;ldquo;Lessons Learned&amp;rdquo;. More important is to take that list and mix
it up - 90% of the failures could be categorized as a permutation of only three
key events. Just two events interacting accounted for 50% of CFs.&lt;/p&gt;

&lt;h4 id=&#34;further-reading:fab8ffd47911301da93228e4cb7d5640&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;ConfErr - tests configuration errors within a realistic range&lt;/li&gt;
&lt;li&gt;MODIST - Model checking for distributed system&lt;/li&gt;
&lt;li&gt;FATE and DESTINI - Framework for cloud recovery testing&lt;/li&gt;
&lt;li&gt;This looks interesting: KLEE - a code-coverage generator for C programs.
  Can&amp;rsquo;t find any examples for Python though, which would be my use-case.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:fab8ffd47911301da93228e4cb7d5640:whitepaper&#34;&gt;&lt;a href=&#34;https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf&#34;&gt;https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf&lt;/a&gt;
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fab8ffd47911301da93228e4cb7d5640:whitepaper&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:fab8ffd47911301da93228e4cb7d5640:catfail&#34;&gt;Failure of the system for a majority to all users.
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:fab8ffd47911301da93228e4cb7d5640:catfail&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>The Aggressive Student</title>
      <link>http://jad-b.github.io/post/The%20Aggressive%20Student/</link>
      <pubDate>Mon, 28 Mar 2016 09:55:02 -0400</pubDate>
      
      <guid>http://jad-b.github.io/post/The%20Aggressive%20Student/</guid>
      <description>

&lt;p&gt;Learning is being in a race against yourself. These things help.&lt;/p&gt;

&lt;h2 id=&#34;the-rapid-acquisistion-of-highly-technical-information:04d7ba831a5d03aab2a2b90cdbe484ff&#34;&gt;The Rapid Acquisistion of Highly-Technical Information&lt;/h2&gt;

&lt;p&gt;Learning very technical information is unique from the general problem of
learning in a few ways. First of all, the end-result is entirely mental. Either
you understand the concepts well enough to accomplish your task, or you do not.
This is in contrast to learning a song on the piano, where a subconscious system
is learning instead, like training motor patterns for rote memorization.&lt;/p&gt;

&lt;p&gt;Imagine your current state of skill or knowledge as a wavefront. Inside its
boundary is your &amp;ldquo;known&amp;rdquo;, and outside is the &amp;ldquo;unknown&amp;rdquo;.
Your awareness of an Unknown item is determined by its distance from the
boundary of this wavefront.&lt;/p&gt;

&lt;p&gt;A few corollaries:
1) You can only learn what lies against this wavefront.
2) You can &amp;ldquo;reach&amp;rdquo; into the Unknown by attempting (and failing) to
This &amp;ldquo;reaching&amp;rdquo; is defined by your failure to completely learn; otherwise,
you&amp;rsquo;d be at step one. However, this primes you to learn the material.&lt;/p&gt;

&lt;p&gt;Imagine casting a net around a topic you don&amp;rsquo;t understand. The &amp;ldquo;net&amp;rdquo; is made of
all the possible connections you can make to this topic; previous training,
analogy to other fields, half-notions of concepts.&lt;/p&gt;

&lt;h3 id=&#34;how-it-feels:04d7ba831a5d03aab2a2b90cdbe484ff&#34;&gt;How it feels&lt;/h3&gt;

&lt;p&gt;The most important feelings I can associate with learning are boredom,
frustration, confusion, and flow.&lt;/p&gt;

&lt;p&gt;Boredom tells you the work is too easy.&lt;/p&gt;

&lt;p&gt;Frustration says you are missing something.&lt;/p&gt;

&lt;p&gt;Confusion says you have over-reached. This is only a bad thing in large
amounts.&lt;/p&gt;

&lt;p&gt;Flow says you&amp;rsquo;ve got it just right. It lies between boredom and confusion.&lt;/p&gt;

&lt;h3 id=&#34;sequencing-when-to-learn-what:04d7ba831a5d03aab2a2b90cdbe484ff&#34;&gt;Sequencing | When to Learn What&lt;/h3&gt;

&lt;p&gt;Find the highest-level summary of the topic you can. Then a slightly more
verbose description. Then yet another more verbosity write-up. Etc., etc.&lt;/p&gt;

&lt;p&gt;When in doubt, jump in. Write down what confuses you. Keep going until the
confusion reaches a point that you can no longer pretend to know what&amp;rsquo;s going
on. The list you&amp;rsquo;ve written is where you&amp;rsquo;ll start tomorrow.&lt;/p&gt;

&lt;h3 id=&#34;spacing-when-to-learn:04d7ba831a5d03aab2a2b90cdbe484ff&#34;&gt;Spacing | When to Learn&lt;/h3&gt;

&lt;p&gt;Learn until one of these two things happen: You feel confused, or you&amp;rsquo;ve
grasped a new topic but wouldn&amp;rsquo;t be able to teach it well yourself. This is
where you&amp;rsquo;ll pick up from.&lt;/p&gt;

&lt;p&gt;As you revisit topics, mix in sources. If you began your exploration with an
online course, try: A blog post, a YouTube video, a textbook.&lt;/p&gt;

&lt;p&gt;The day after learning, review your notes.  The next day, summarize them. Where
possible, use drawings and analogy.&lt;/p&gt;

&lt;h2 id=&#34;basic-tips:04d7ba831a5d03aab2a2b90cdbe484ff&#34;&gt;Basic tips&lt;/h2&gt;

&lt;p&gt;Only highlight/underline what you don&amp;rsquo;t understand. It doesn&amp;rsquo;t help you
remember, but it does help you find the gaps when you revisit the material.
Use some kind of notation for removing highlights as you do comprehend the
gaps.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>On Learning</title>
      <link>http://jad-b.github.io/post/On%20Learning/</link>
      <pubDate>Sat, 10 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>http://jad-b.github.io/post/On%20Learning/</guid>
      <description>

&lt;p&gt;This document will serve as a case study on learning, using learning databases as the problem.&lt;/p&gt;

&lt;h3 id=&#34;glossay:7a16559f2e7bb44f60862eae17319468&#34;&gt;Glossay&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;grounding&lt;/strong&gt; give (something abstract) a firm theoretical or practical basis&lt;/p&gt;

&lt;h2 id=&#34;concepts:7a16559f2e7bb44f60862eae17319468&#34;&gt;Concepts&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;&amp;hellip;and what matters most is Understanding. And Understanding starts with &amp;ldquo;What Matters&amp;rdquo; - &lt;a href=&#34;http://www.quora.com/How-do-I-get-started-in-Artificial-Intelligence&#34;&gt;Quora: Forays into AI&lt;/a&gt;
because we get better with practice as we get more experience, which is a hallmark of any Intuition based skill - &lt;a href=&#34;http://syntience.com/rch.pdf&#34;&gt;Reductionism Considered Harmful&lt;/a&gt;
This is another hallmark of Intuition based skills: they cannot be taught as high level rules, they have to be experienced bottom up. This is, incidentally, also the difference between Teaching and Coaching - [ibid]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using features of the information to classifying &amp;amp; divide concepts.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Begin with the problem space. Overview of &amp;ldquo;Why are we learning this? What are the fundamental problems this is trying to address?&amp;rdquo; Try and use a &lt;em&gt;concrete&lt;/em&gt; example; &lt;em&gt;ground&lt;/em&gt; it.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why do we use databases? We need ways to manage incredibly large sets of data and its metadata. Metadata can include the relationships within data.

&lt;ul&gt;
&lt;li&gt;This grounds the upcoming concept against the student&amp;rsquo;s pre-existing
patterns.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;What problems do databases have to solve? Writing to disk is very slow compared to the rest of I/O, so all databases need to optimize this. How they do so is a significant difference between databases.

&lt;ul&gt;
&lt;li&gt;We can use this difference as a means of classifying and comparing different databases.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Provide a framework for comparison&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Would listing up-front the variables for comparison overwhelm or assist? Perhaps this is size-dependent on the number of variables.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Use a common example across the different categories&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For databases, have a given set of data, and depict how it&amp;rsquo;s stored in different DBs.&lt;/li&gt;
&lt;li&gt;In military terms, this would be the &amp;ldquo;walk&amp;rdquo; phase - hand-holding still involved. The &amp;ldquo;run&amp;rdquo; might be creating a data set, and having the student depict the different style of storage.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;techniques:7a16559f2e7bb44f60862eae17319468&#34;&gt;Techniques&lt;/h2&gt;

&lt;p&gt;Tim Ferris promotes &lt;code&gt;DSSS&lt;/code&gt; and it&amp;rsquo;s sub-steps, &lt;code&gt;CaFE&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;DSSS&lt;/strong&gt;

&lt;ol&gt;
&lt;li&gt;Deconstruction

&lt;ul&gt;
&lt;li&gt;Reducing&lt;/li&gt;
&lt;li&gt;Interviewing&lt;/li&gt;
&lt;li&gt;Reversal&lt;/li&gt;
&lt;li&gt;Translating&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Selection (The &lt;sup&gt;80&lt;/sup&gt;&amp;frasl;&lt;sub&gt;20&lt;/sub&gt; rule)&lt;/li&gt;
&lt;li&gt;Sequencing (The order in which you choose to learn)&lt;/li&gt;
&lt;li&gt;Stakes (The carrot &amp;amp; the stick)&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CaFE&lt;/strong&gt;

&lt;ol&gt;
&lt;li&gt;Compression

&lt;ul&gt;
&lt;li&gt;How can I represent the essential 20% in a compact reference?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Frequency

&lt;ul&gt;
&lt;li&gt;What is most sustainable schedule I can manage for learning this information?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Encoding

&lt;ul&gt;
&lt;li&gt;How can I leverage anchors, connections, and whatever tricks possible to make this information stick?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;recursive-horizon-expansion:7a16559f2e7bb44f60862eae17319468&#34;&gt;Recursive Horizon Expansion&lt;/h3&gt;

&lt;h4 id=&#34;phase-1-unknown-unknown-s:7a16559f2e7bb44f60862eae17319468&#34;&gt;Phase 1) Unknown Unknown&amp;rsquo;s&lt;/h4&gt;

&lt;p&gt;Read summaries
Gather resources
Identify major questions and early stumbling blocks. For instance, machine
Learning requires linear algebra basics from the get-go, and an intermediate
skills in such in order to understand things like PCA.&lt;/p&gt;

&lt;h4 id=&#34;phase-2-intake:7a16559f2e7bb44f60862eae17319468&#34;&gt;Phase 2) Intake&lt;/h4&gt;

&lt;p&gt;Read through material until confused (diminishing returns), or 45 minutes.
Perform an assessment of prevous material.&lt;/p&gt;

&lt;h4 id=&#34;phase-3-understand:7a16559f2e7bb44f60862eae17319468&#34;&gt;Phase 3) Understand&lt;/h4&gt;

&lt;p&gt;Do; else, teach.&lt;/p&gt;

&lt;h2 id=&#34;explaining-101:7a16559f2e7bb44f60862eae17319468&#34;&gt;Explaining, 101&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;What the hell is it?

&lt;ul&gt;
&lt;li&gt;As explained in terms I already know. Or if there&amp;rsquo;s no way for this to
relate it to me without explaining something else, start there.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Why do I need it?

&lt;ul&gt;
&lt;li&gt;Why is this relevant? Why are people excited?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
  </channel>
</rss>