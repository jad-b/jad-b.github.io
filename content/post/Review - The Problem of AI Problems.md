+++
categories = ["machine learning"]
date = "2016-06-13T07:40:14-04:00"
tags = ["review"]
title = "Review - The Problem of AI Problems"
draft = "true"
+++

Syntience[Syntience] is pursuing AGI through an _epistomological_ approach

<!--more-->

### [The Problem of AI Problems]
* In summary, Understanding is more important than Reasoning
* The human mind is not inherently scientific (empirical).
* It is an incredibly effective tool at quickly arriving at an answer from incomplete information;[System One]
* It leverages heuristics (a.k.a "biases") heavily. Of course, some people think we just have the wrong model)[Not
  Another Bias]
* Once you accept our understanding is Intuitive, you need ways to figure out "What Matters" - what is relevant, and
  what is not, to the situation at hand.
* This is a core problem for AI's. They need feedback, some kind of cost, and they're still at the mercy of us telling
  them what does and does not matter.  We call this ability to judge problem-space relevancy "Saliency"
  * The big-win here would be called "domain-independent saliency"
* Once you know what is salient to your problem, you need to find your way towards the answer to problems using
  epsitemology - _not_ Reductionism.

[Syntience]: http://syntience.com/links.html
[System One]: https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow
[The Problem of AI Problems]: http://www.quora.com/How-do-I-get-started-in-Artificial-Intelligence
[Not Another Bias]: http://jasoncollins.org/2015/07/30/please-not-another-bias-an-evolutionary-take-on-behavioural-economics/
